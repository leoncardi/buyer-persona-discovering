{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Stages Overview__ <br>\n",
    "[&gt; 1. IDA](01-initial-data-analysis.ipynb) [&gt; 2. EDA](02-exploratory-data-analysis.ipynb) [&gt; 3. Feature Eng.](03-feature-engineering.ipynb) [&gt; 4. Modeling & Evaluation](04-modeling-and-evaluation.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. INITIAL DATA ANALYSIS: Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Briefing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Identify and resolve potential quality issues in the research raw data, to ensuring a ready dataset for progression through the research stages.\n",
    "    - Summary: identify > resolve > quality issues > raw data > research progression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debriefing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Data issues were discussed, identified and sucessfully resolved in the following subjects:\n",
    "    - Duplicates Data;\n",
    "    - Missing Values/Data Loss;\n",
    "    - Format/Type of Data;\n",
    "    - Outliers.\n",
    "- #### Pre-processed datasets were generated with quality, and allowed the research to progress to the next stages.\n",
    "    - Summary: pre-processed > raw data > with quality > allowed > research progression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materials and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Data overview__\n",
    "    - The Online Retail II UCI is the dataset of this data science research in its raw (original) state, without any treatment, cleaning and inspection.\n",
    "- __Online Retail II UCI description__ \n",
    "    - \"A real online retail transaction data set of two years. Dataset contains all the transactions occurring for a UK-based and registered, non-store online retail between 01/12/2009 and 09/12/2011. The company mainly sells unique all-occasion gift-ware. Many customers of the company are wholesalers.\"\n",
    "- __Online Retail II UCI data dictionary__\n",
    "    - __Invoice__: Invoice number. Nominal. A 6-digit integral number uniquely assigned to each transaction. If this code starts with the letter 'c', it indicates a cancellation;\n",
    "    - __StockCode__: Product (item) code. Nominal. A 5-digit integral number uniquely assigned to each distinct product;\n",
    "    - __Description__: Product (item) name. Nominal;\n",
    "    - __Quantity__: The quantities of each product (item) per transaction. Numeric;\n",
    "    - __InvoiceDate__: Invice date and time. Numeric. The day and time when a transaction was generated;\n",
    "    - __UnitPrice__: Unit price. Numeric. Product price per unit in sterling (Â£);\n",
    "    - __CustomerID__: Customer number. Nominal. A 5-digit integral number uniquely assigned to each customer;\n",
    "    - __Country__: Country name. Nominal. The name of the country where a customer resides.\n",
    "- __Dataset source | Dataset info and dictionary source__\n",
    "    - https://www.kaggle.com/datasets/mashlyn/online-retail-ii-uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = './data/raw_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Pandas__\n",
    "    - DataFrames and Series for data manipulation, analysis and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from src.utils.analytics import DataIssues \n",
    "import os current_directory = os.getcwd() \n",
    "if os.path.basename(current_directory) == 'notebooks': \n",
    "    os.chdir('..') \n",
    "    from utils.analytics import DataIssues\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# raw_data = pd.read_csv(raw_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. O dicionário oficial dos dados brutos forneceu informações essenciais sobre a estrutura dos dados, facilitando a compreensão eficiente do seu formato e conteúdo. Esse recurso foi crucial para orientar a preparação e análise subsequentes dos dados. E comparar se os dados brutos estão em conformidade com o dicionário oficial é uma etapa crítica para garantir a qualidade e a integridade dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. O Pandas foi utilizado para verificar a conformidade da estrutura dos dados, realizar avaliações e implementar o tratamento necessário. Os processos realizados incluíram a detecção de dados duplicados, valores faltantes, formatos inadequados e outliers. Diversas fontes e citações ressaltaram a importância de preparar adequadamente os dados, uma vez que dados mal preparados podem não ser aceitos por algoritmos de aprendizado de máquina e podem complicar a análise de dados.\n",
    "\n",
    "3. The raw data for the study consists of over one million observations. Due to the large volume and quality issues identified in the data structure, the primary approach adopted was to remove the compromised data entirely, without applying significance tests. This approach aims to prioritize obtaining data of sufficient quality for analysis and modeling, while balancing compliance with the study’s timelines. While removal without significance analysis may have limitations, steps were taken to keep all data and processes thoroughly documented in the study repository. This will allow the documentation to provide a solid foundation for future investigations and contribute to the accumulated knowledge about the business problem at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "rdi = DataIssues(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdi.count_missing_data_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdi.get_data_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdi.count_outliers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUTS (identification __issues overview__, actions to __resolving__ and full __preprocessing__ implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### The raw data has __six variables__ with __quality issues__ that need to be __resolved__.\n",
    "\n",
    "- ### Identifi**ed** Data Issues In:\n",
    "    - #### Missing Values/Data Loss:\n",
    "        - `Description` (4,382 missing values)\n",
    "        - `Customer ID` (243,007 missing values)\n",
    "    - #### Format/Type of Data:\n",
    "        - `InvoiceDate` (needs to be converted to datetime)\n",
    "        - `Customer ID` (needs to be converted to object)\n",
    "    - #### Outliers:\n",
    "        - `Quantity` (has 116,489 outliers)\n",
    "        - `Price` (has 68,105 outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_to_preprocess__missings_types_outliers = raw_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_missing_data_issues(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "raw_data_to_preprocess__types_outliers= resolve_missing_data_issues(raw_data_to_preprocess__missings_types_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_data_types(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = data.copy()\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['InvoiceDate']):\n",
    "        df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    if not pd.api.types.is_string_dtype(df['Customer ID']):\n",
    "        df['Customer ID'] = df['Customer ID'].astype(int)\n",
    "        df['Customer ID'] = df['Customer ID'].astype(str) \n",
    "    return df\n",
    "raw_data_to_preprocess__outliers = resolve_data_types(raw_data_to_preprocess__types_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize the data\n",
    "preprocessed_data__with_outliers = raw_data_to_preprocess__outliers\n",
    "\n",
    "del raw_data_to_preprocess__missings_types_outliers\n",
    "del raw_data_to_preprocess__types_outliers\n",
    "del raw_data_to_preprocess__outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_outliers_iteratively(data: pd.DataFrame, max_iterations=100) -> (pd.DataFrame, pd.DataFrame):\n",
    "    \n",
    "    all_outliers = pd.DataFrame()    \n",
    "    for i in range(max_iterations):\n",
    "        df_with_outliers = data.copy()\n",
    "        \n",
    "        for column in df_with_outliers:\n",
    "            if pd.api.types.is_numeric_dtype(df_with_outliers[column]):\n",
    "                Q1 = df_with_outliers[column].quantile(0.25)\n",
    "                Q3 = df_with_outliers[column].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                print(f'i{i + 1} | variable: {column} - lower bound: {lower_bound} <-> upper bound: {upper_bound}')\n",
    "\n",
    "                df_with_outliers[f'outlier_{column}'] = (df_with_outliers[column] < lower_bound) | (df_with_outliers[column] > upper_bound)\n",
    "        \n",
    "        outlier_columns = [col for col in df_with_outliers.columns if col.startswith('outlier_')]\n",
    "        df_with_outliers['is_outlier'] = df_with_outliers[outlier_columns].any(axis=1)\n",
    "        \n",
    "        df_without_outliers = df_with_outliers[~df_with_outliers['is_outlier']].copy()\n",
    "        new_isolated_outliers = df_with_outliers[df_with_outliers['is_outlier']].copy()\n",
    "        \n",
    "        all_outliers = pd.concat([all_outliers, new_isolated_outliers], ignore_index=True)\n",
    "        \n",
    "        df_without_outliers.drop(outlier_columns + ['is_outlier'], axis=1, inplace=True)\n",
    "        \n",
    "        if df.shape[0] == df_without_outliers.shape[0]:\n",
    "            print(f'No more outliers detected in iteration {i + 1}.')\n",
    "            print('Dataset is now outlier-free.')\n",
    "            break\n",
    "        \n",
    "        df = df_without_outliers\n",
    "    \n",
    "    return df, all_outliers\n",
    "preprocessed_data, preprocessed_data_isolated_outliers = resolve_outliers_iteratively(preprocessed_data__with_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL RESULTS - INITIAL (RAW) DATA ANALYSIS: Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### The raw data were __successfully preprocessed__ and reached a __sufficient level of quality__ to be __ready__ for progression to the next stages of the study.\n",
    "\n",
    "### __Resolved__ Data Issues In:\n",
    "- #### Missing Values/Data Loss:\n",
    "    - `Description` (4,382 missing values) -> __dropped__\n",
    "    - `Customer ID` (243,007 missing values) -> __dropped__\n",
    "- #### Format/Type of Data:\n",
    "    - `InvoiceDate` (needs to be converted to datetime) -> __converted__\n",
    "    - `Customer ID` (needs to be converted to object) -> __converted__\n",
    "- #### Outliers:\n",
    "    - `Quantity` (has 116,489 outliers) -> __resolved__\n",
    "    - `Price` (has 68,105 outliers) -> __resolved__\n",
    "\n",
    "- #### New genereted preprocessed datasets:\n",
    "    - `preprocessed_data` -> __Final pre-processed data__\n",
    "    - `preprocessed_data_isolated_outliers` -> Isolated outliers from the final pre-processed data\n",
    "    - `preprocessed_data__with_outliers` -> Final pre-processed data (__WITH__ outliers)\n",
    "- #### Limitations:\n",
    "    - Although the transformation performed in this initial data preparation is essential to advance the analysis and modeling, it can lead to the loss of valuable information, introduce bias, and reduce the representativeness of the data, compromising the precision of the results. In a future study on this business problem and the data involved, it is essential to assess the impact of data loss using reliable and well-established statistical techniques. However, despite the removals performed, the study preserved 61.69% of the original observations, keeping all variables and excluding 408,871 observations that contained missing data or outliers in any of their variables.\n",
    "- #### Implications:\n",
    "    - During the initial analysis of the data, over 160,000 outliers were identified. None of these outliers were discarded. Although they were not used in the current modeling, they were isolated and stored in the study repository and may serve as a basis for analysis in future research.\n",
    "- #### Next steps:\n",
    "    - __Exploratory Data Analysis (EDA)__\n",
    "    - __Modeling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short comparison between raw and preprocessed data\n",
    "print('RAW DATA:')\n",
    "display(raw_data)\n",
    "print()\n",
    "print('PREPROCESSED DATA:')\n",
    "display(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdi = DataIssues(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdi.count_missing_data_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdi.get_data_types()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdi.count_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(data: pd.DataFrame, path: str) -> None:\n",
    "    data.to_csv(path, index=False)\n",
    "    print('A dataset was exported successfully to: ', path)\n",
    "    return None\n",
    "\n",
    "export_data(preprocessed_data, './data/preprocessed_data.csv')\n",
    "export_data(preprocessed_data_isolated_outliers, './data/preprocessed_data_isolated_outliers.csv')\n",
    "export_data(preprocessed_data__with_outliers, './data/preprocessed_data__with_outliers.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
